# ğŸ¤– Multi-Agent Dashboard

## ğŸ“– Overview

**Multi-Agent Dashboard** is a Streamlit-based Python application for building, managing, and running multi-agent LLM pipelines with:

- ğŸ§  Reusable, UI-agnostic execution engine
- ğŸ’¾ Persistent SQLite storage
- ğŸ‘€ Rich observability (cost, latency, logs, history)
- ğŸ§° Tool calling (incl. web search) with per-agent controls

Use it to prototype agent workflows, compare models and prompts, inspect tool usage, and keep a detailed history of runs.

The project uses a **standard `src/` Python package layout** for clean imports and long-term maintainability.

---

## âš¡ Quick Start (TL;DR)

1. **Clone & enter repo**

   ```bash
   git clone <your-repo-url>
   cd <repo-root>
   ```

2. **Create & activate a virtualenv (recommended)**

   ```bash
   python -m venv .venv
   source .venv/bin/activate        # macOS / Linux
   # .venv\Scripts\activate         # Windows
   ```

3. **Install in editable mode**

   ```bash
   pip install -e .
   ```

   Note: Installing in editable mode is recommended so the `multi_agent_dashboard` package is importable in your environment. See the "How to run commands" note below if you prefer not to install.

   Important: module-style commands shown elsewhere in this README (for example, `python -m multi_agent_dashboard.db.infra.generate_migration ...`) require that the package be importable in your environment â€” e.g. after `pip install -e .` or with `PYTHONPATH` including `src/`. If you prefer not to install, run the helper scripts directly from the repository root, e.g.:

   ```bash
   python src/multi_agent_dashboard/db/infra/generate_migration.py ...
   ```

4. **Configure environment**

   Create `.env` in the project root:

   ```text
   OPENAI_API_KEY=your_api_key_here
   LOG_LEVEL=INFO
   ```

5. **Run the dashboard**

   From the project root:

   ```bash
   streamlit run src/multi_agent_dashboard/ui/app.py
   ```

6. **Open the app**

   ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

On first run, the app will:

- Create `data/` and subdirectories (if missing)
- Initialize SQLite at `data/db/multi_agent_runs.db`
- Apply SQL migrations from `data/migrations/`
- Seed default agents if the DB is empty

Quick note â€” How to run CLI scripts
- Module-style (recommended for examples in this README):
  - `python -m multi_agent_dashboard.db.infra.generate_migration ...`
  - Requires the package to be importable, i.e. `pip install -e .` (or appropriate PYTHONPATH).
- Direct script invocation (works without `pip install -e .`):
  - Run the helper script from the repository top-level, e.g.:
    - `python src/multi_agent_dashboard/db/infra/generate_migration.py ...`
  - This can be handy for quick one-off runs when you don't want to install the package.

---

## ğŸ§© System Requirements

- ğŸ **Python**: >=3.10 (tested with CPython 3.14)
- ğŸ’» **OS**: Tested on macOS; should work on Linux and Windows with appropriate environment setup
- ğŸŒ **Network**: Outbound HTTPS access to OpenAIâ€™s APIs
- ğŸ”‘ **Credentials**: Valid `OPENAI_API_KEY` in `.env`

Note: pandas (and numpy) are installed as direct dependencies of Streamlit, so you generally won't need to pip install `pandas` separately for the UI/analytics workflows that rely on Streamlit. (See Streamlit docs.) ([docs.streamlit.io](https://docs.streamlit.io/deploy/concepts/dependencies?utm_source=openai))

---

## âš™ï¸ Configuration Reference

Most configuration is centralized in `config.py` and `.env`.

### ğŸŒ± Environment Variables (`.env` at project root)

| Name            | Required | Default | Description                                      |
|-----------------|----------|---------|--------------------------------------------------|
| `OPENAI_API_KEY`| âœ…       | None    | OpenAI API key used by the LLM client           |
| `LOG_LEVEL`     | âŒ       | `INFO`  | Global logging level (`DEBUG`, `INFO`, `WARNING`, `ERROR`) |

If `OPENAI_API_KEY` is missing or invalid, LLM calls will fail at runtime; the UI may load but requests to the model will error.

### ğŸ§± Core Paths & Caps (from `config.py`)

| Setting              | Default                          | Description                                      |
|----------------------|----------------------------------|--------------------------------------------------|
| `PROJECT_ROOT`       | Repo root                       | Auto-detected project root                       |
| `DATA_PATH`          | `PROJECT_ROOT / "data"`         | Root for data and artifacts                      |
| `DB_PATH`            | `DATA_PATH / "db"`              | Directory for SQLite databases                   |
| `DB_FILE_PATH`       | `data/db/multi_agent_runs.db`   | Main SQLite DB file (auto-created)              |
| `MIGRATIONS_PATH`    | `data/migrations`               | Ordered SQL migrations                           |
| `LOGS_PATH`          | `data/logs`                     | Log directory for rotating app logs              |
| `AGENT_INPUT_CAP`    | defined in `config.py`          | Max characters per formatted input segment       |
| `AGENT_OUTPUT_CAP`   | defined in `config.py`          | Max characters per rendered prompt / output      |

Prompt formatting and outputs are passed through `utils.safe_format` using these caps to avoid unbounded prompt sizes.

---

## ğŸš€ Getting Started (Detailed)

### 1ï¸âƒ£ Clone the repository

```bash
git clone <your-repo-url>
cd <repo-root>
```

### 2ï¸âƒ£ Create and activate a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate        # macOS / Linux
# .venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Install the project in editable mode

This is **required** when using a `src/` layout so that `multi_agent_dashboard` is importable:

```bash
pip install -e .
```

(If you prefer not to install, see the Quick Start note above for how to invoke helper scripts directly.)

### 4ï¸âƒ£ Configure environment variables

Create a `.env` file in the project root:

```text
OPENAI_API_KEY=your_api_key_here
LOG_LEVEL=INFO
```

You can adjust the log level (e.g. `DEBUG`) while developing.

### 5ï¸âƒ£ Run the dashboard

From the project root:

```bash
streamlit run src/multi_agent_dashboard/ui/app.py
```

Then open:

ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

### 6ï¸âƒ£ First Run Behavior

On first successful run, the app will:

- Ensure `data/`, `data/db/`, `data/logs/`, and `data/migrations/` exist
- Create the SQLite DB at:

  ```text
  data/db/multi_agent_runs.db
  ```

- Apply all SQL migrations from `data/migrations/` using the centralized migration system
- Seed default agents (planner/solver/critic/finalizer-style roles) if the `agents` table is empty
- Initialize a rotating log file under `data/logs/` (see Logging below)

### ğŸ©º Troubleshooting First Run

- â— **No API key or invalid key**
  - Symptom: UI loads, but model calls fail with authentication/authorization errors.
  - Fix: Set `OPENAI_API_KEY` in `.env`, restart Streamlit.

- â— **Permission issues**
  - Symptom: Errors writing to `data/db` or `data/logs`.
  - Fix: Ensure you have write permissions in the repo directory; adjust Docker/container volume mounts if applicable.

- â— **Python version errors**
  - Symptom: Syntax errors on union types (`str | None`) or similar.
  - Fix: Use Python >=3.10; this project is tested with CPython 3.14 (upgrade your interpreter if you encounter syntax incompatibilities).

---

## ğŸ§­ Usage

The UI is organized into distinct modes (tabs/pages inside the Streamlit app):

### ğŸ‘¤ Agent Management

Manage reusable agent definitions:

- ğŸ›ï¸ Create, edit, duplicate, delete, rename, and import agents
- ğŸ§© Configure:
  - Model, role, and system prompts
  - Inputs & outputs (with contract validation)
  - Tools (including web search) and reasoning behavior
  - Allowed domains per agent for web tools
  - Color and symbol used in graphs and selectors
- ğŸ•’ Inspect versioned prompt history per agent

Agents are persisted to SQLite and safely versioned, so you can inspect older prompts and configurations.

### ğŸ”— Pipelines (Run Mode)

Build and execute multi-agent pipelines:

- ğŸ”€ Construct pipelines from agents, including:
  - Named, reusable pipelines
  - Ad-hoc pipelines using the current session state
- â–¶ï¸ Run pipelines and inspect:
  - Per-agent inputs and outputs
  - Tool calls and reasoning traces
  - Execution warnings and contract violations
- ğŸ“¤ Export:
  - Pipeline definitions and associated agents as JSON (pipeline-agent export)
  - Final and intermediate outputs for offline analysis

### ğŸ•’ History

Review and analyze previous runs:

- ğŸ“š Browse historical runs stored in SQLite with rich metadata:
  - Models, agent configs, JSON/markdown flags, timing
- ğŸ‘€ Inspect per-run and per-agent outputs
- ğŸ” Compare outputs between agents using a unified diff tool
- ğŸ“Š View cost & latency metrics:
  - Per-run and per-agent cost breakdowns
  - Separate input/output token costs stored alongside totals
- ğŸ“¦ Export full run records (including agent configs and metrics) as JSON

### ğŸ“ File Attachments

Augment runs with files:

- ğŸ“ Attach files to agents and runs
- ğŸ§¬ Automatic MIME-type detection & size limits enforced centrally
- Supports mixed text/binary LLM calls where supported by the model / API

### ğŸ“œ Logs & Observability

Monitor and debug live behavior:

- ğŸ“š Built-in log viewer reads from a rotating log file
- ğŸ¨ Color-coded log levels with search, filters, download, and live updates
- ğŸ§  Logs are written via centralized configuration in `config.py` to both stdout and `data/logs/`

---

## âœ¨ Key Features

### ğŸ§  Engine & Contracts

- ğŸ¤– Multi-agent pipeline execution with a unified dashboard UI
- ğŸ§© Dynamic agent configuration (model, role, inputs/outputs, tools, reasoning behavior, colors, symbols)
- ğŸ§  Strict vs permissive execution modes:
  - Strict mode with explicit input/output contracts and writeback behavior
  - Permissive mode for easier experimentation
- ğŸ§¾ Rich output metadata:
  - JSON vs markdown flags
  - Model identifiers and execution context

### ğŸ”Œ Tools & Reasoning

- ğŸ›  Tool calling:
  - Optional web search tools
  - Per-agent domain restrictions
  - Tool-call traces and agent configurations persisted with each run
- ğŸ§  Reasoning controls:
  - Configurable reasoning effort / style per agent where supported
  - Persisted reasoning and tool-usage configuration per run

### ğŸ’¾ Database & Migrations

- ğŸ’¾ SQLite-backed persistence:
  - Agents and versioned prompts
  - Pipelines and pipeline steps
  - Runs, per-agent outputs, and metrics
- ğŸ§± Centralized migration system:
  - Canonical schema in `db/infra/schema.py`
  - Migration generator (`generate_migration.py`) with FK-aware diffing
  - SQL migrations under `data/migrations/` (e.g. `000_*.sql`, `001_*.sql`, â€¦)
- ğŸ” Foreign key & constraint management:
  - Migrations that require constraint rebuild are tagged with `_REQUIRES_REBUILD`
  - On **fresh (empty) databases**, relevant tables are auto-rebuilt when those migrations run
  - On existing (non-empty) databases, you must run `sqlite_rebuild.py` explicitly for safe rebuilds

### ğŸ“Š Monitoring & Metrics

- ğŸ“Š Cost & latency profiling:
  - Per-run and per-agent metrics with:
    - Input vs output token/cost breakdown
    - Aggregated per-run cost/latency summaries
  - Metrics are persisted and included in JSON exports
- ğŸ‘€ Pipeline visualization:
  - Agent graph view with per-agent colors and symbols
  - Performance and cost overlays

### ğŸ“¤ Import/Export

- ğŸ“¥ Import agent definitions via JSON templates in the UI
- ğŸ“¤ Export:
  - Pipelines + their agents (pipeline-agent export)
  - Per-run history including agent configs, outputs, metrics, and tool usage
- ğŸ§­ Enhanced run selector:
  - Displays run ID, timestamp, agent execution order, and abbreviated task

---

## ğŸ—ï¸ Architecture Overview

The project is organized into clear layers:

- ğŸ›ï¸ **UI Layer (`ui/`)**
  - `ui/app.py`: Streamlit app
  - Handles presentation and user interaction
  - Talks only to services, engine, and models â€” not directly to DB internals

- ğŸ§° **Service Layer (`db/services.py`)**
  - `AgentService`, `RunService`, `PipelineService`
  - Transactional APIs for the UI and scripts
  - Orchestrates DAOs and engine operations

- ğŸ—ƒï¸ **Persistence Layer (`db/*.py`)**
  - DAOs:
    - `agents.py` â€“ agent persistence & prompt versions
    - `pipelines.py` â€“ pipeline specs and steps
    - `runs.py` â€“ run records, outputs, metrics
  - `db.py` â€“ backwards-compatible DB entry points, re-exporting DAOs and providing `init_db`

- ğŸ§± **DB Infrastructure (`db/infra/`)**
  - `core.py` â€“ connection and migrations bootstrap
  - `schema.py` â€“ canonical schema
  - `migrations.py` â€“ migration application logic
  - `generate_migration.py` â€“ CLI to generate migrations from `schema.py`
  - `schema_diff.py`, `schema_diff_constraints.py` â€“ schema diff tools
  - `sqlite_rebuild.py` â€“ safe table rebuild helpers & CLI

- ğŸ§  **Engine & LLM Client**
  - `engine.py` â€“ core multi-agent orchestration engine (UI-agnostic)
  - `llm_client.py` â€“ OpenAI client abstraction with:
    - Typed errors
    - Retries & backoff
    - Tool-calling support
    - Normalized responses for the engine

- ğŸ§© **Models & Utilities**
  - `models.py` â€“ domain models:
    - `AgentSpec`, `AgentRuntime`, `PipelineSpec`, run result types, etc.
  - `utils.py` â€“ shared helpers, including `safe_format` with centralized caps
  - `config.py` â€“ global configuration (paths, pricing tables, logging, caps, colors, symbols)

A typical flow:

```text
UI (Streamlit)
  â†’ Services (AgentService / RunService / PipelineService)
    â†’ DAOs (agents / pipelines / runs)
      â†’ DB (SQLite)
  â†’ Engine (orchestrates agents & LLM calls)
    â†’ LLMClient (OpenAI Responses API + tools)
```

---

## ğŸ—‚ï¸ Repository Structure

```text
repo_root/
â”œâ”€â”€ .env                         # Environment variables (API keys, log level; not committed)
â”œâ”€â”€ .gitignore                   # Ignore sensitive/generated files
â”œâ”€â”€ LICENSE                      # Project license
â”œâ”€â”€ pyproject.toml               # Project metadata, dependencies, packaging config
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ src/
â”‚   â””â”€â”€ multi_agent_dashboard/   # Main Python package (src layout)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py            # Paths, logging, pricing, UI theming, caps
â”‚       â”œâ”€â”€ engine.py            # Core multi-agent orchestration engine
â”‚       â”œâ”€â”€ llm_client.py        # LLM client abstraction (retries, tools, backoff, errors)
â”‚       â”œâ”€â”€ models.py            # Domain models (AgentSpec, PipelineSpec, etc.)
â”‚       â”œâ”€â”€ utils.py             # Shared utilities (safe_format, helpers)
â”‚       â”œâ”€â”€ db/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ agents.py        # Agent DAOs and helpers
â”‚       â”‚   â”œâ”€â”€ db.py            # Backwards-compatible DB entry points + init_db
â”‚       â”‚   â”œâ”€â”€ pipelines.py     # Pipeline DAOs and helpers
â”‚       â”‚   â”œâ”€â”€ runs.py          # Run/agent output DAOs, metrics persistence
â”‚       â”‚   â”œâ”€â”€ services.py      # AgentService, RunService, PipelineService
â”‚       â”‚   â””â”€â”€ infra/
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â”œâ”€â”€ core.py                    # Connection, migrations bootstrap
â”‚       â”‚       â”œâ”€â”€ generate_migration.py      # Migration generator CLI
â”‚       â”‚       â”œâ”€â”€ migrations.py              # Migration application logic
â”‚       â”‚       â”œâ”€â”€ schema.py                  # Canonical schema definition
â”‚       â”‚       â”œâ”€â”€ schema_diff.py             # Column-level diffing
â”‚       â”‚       â”œâ”€â”€ schema_diff_constraints.py # FK / constraints diffing
â”‚       â”‚       â””â”€â”€ sqlite_rebuild.py          # Safe table rebuild helpers & CLI
â”‚       â””â”€â”€ ui/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ agent_editor_mode.py  # Agent CRUD + prompt versioning UI
â”‚           â”œâ”€â”€ app.py                # Streamlit app entrypoint & mode routing
â”‚           â”œâ”€â”€ bootstrap.py          # App setup: DB, clients, engine, defaults
â”‚           â”œâ”€â”€ cache.py              # Streamlit caching helpers
â”‚           â”œâ”€â”€ exports.py            # Pipeline/run export helpers
â”‚           â”œâ”€â”€ graph_view.py         # Pipeline graph visualization
â”‚           â”œâ”€â”€ history_mode.py       # Past runs viewer & export UI
â”‚           â”œâ”€â”€ logging_ui.py         # Log viewer & Streamlit log handler
â”‚           â”œâ”€â”€ metrics_view.py       # Cost & latency metrics UI
â”‚           â”œâ”€â”€ run_mode.py           # Run configuration, execution, results UI
â”‚           â”œâ”€â”€ styles.py             # Streamlit CSS helpers
â”‚           â”œâ”€â”€ tools_view.py         # Tool usage & per-agent tool UI
â”‚           â”œâ”€â”€ utils.py              # UI utility helpers
â”‚           â””â”€â”€ view_models.py        # UI view-model transformations
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ multi_agent_runs.db  # Auto-created SQLite database (not tracked)
â”‚   â”œâ”€â”€ logs/                    # Rotating log files
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 000_*.sql
â”‚       â”œâ”€â”€ 001_*.sql
â”‚       â”œâ”€â”€ 002_*.sql
â”‚       â””â”€â”€ ...                  # Future migrations
â””â”€â”€ tests/                       # Tests (may be empty / future expansion)
```

> ğŸ“ Note: The `data/` directory and its contents are typically created automatically at runtime. The exact set of migration files will evolve over time; see `data/migrations/` in your clone.

---

## ğŸ§¬ Database & Migration Workflow

Database schema management is centralized in `db/infra`.

### ğŸ”§ Initialization

- `init_db(db_path: Path)` (from `db/db.py` and infra) is the canonical way to:
  - Open a connection
  - Ensure migration tracking is set up
  - Apply all pending migrations from `data/migrations/` against the DB file

The Streamlit UI calls this automatically when you run `app.py`.

### ğŸ§± Schema & Migrations

- **Canonical schema**: `db/infra/schema.py`
- **Migrations**: Ordered SQL files in `data/migrations/` (e.g. `000_create_base_tables.sql`, `001_add_agent_output_metadata.sql`, â€¦)
- **Migration application**: `db/infra/migrations.py`:
  - Tracks applied migrations in a dedicated table
  - Applies new migrations in order

### ğŸ§­ Recommended safe workflow (concise)

Follow this checklist to reduce errors when changing schema:

1. Update the canonical schema:
   - Edit `src/multi_agent_dashboard/db/infra/schema.py` to model the intended change.
2. Preview changes (dry-run):
   - After installing the package (recommended), run:
     ```bash
     python -m multi_agent_dashboard.db.infra.generate_migration my_change --dry-run
     ```
   - Or run the script directly from repo top if not installed:
     ```bash
     python src/multi_agent_dashboard/db/infra/generate_migration.py my_change --dry-run
     ```
   - Review the diff output carefully.
3. Generate migration SQL files:
   ```bash
   python -m multi_agent_dashboard.db.infra.generate_migration my_change
   ```
   (or run the script directly if you didn't install the package)
   - This writes SQL under `data/migrations/` (e.g. `000_...`, `001_...`).
4. Apply migrations:
   - Start the app (or run a script which calls `init_db`) to apply migrations; `init_db` will apply new migrations automatically.
5. Handle `_REQUIRES_REBUILD` migrations:
   - If the migration filename includes `_REQUIRES_REBUILD` and your DB is non-empty, run the safe rebuild tool:
     ```bash
     python -m multi_agent_dashboard.db.infra.sqlite_rebuild --all-with-diffs data/db/multi_agent_runs.db
     ```
     (This tool creates backups before destructive operations. Use `--dry-run` to preview.)
   - If your DB is fresh (no user tables or all user tables empty), the migration system may auto-rebuild those tables for you during init; otherwise, use `sqlite_rebuild.py` to make the rebuild explicit and safe.

Note about "fresh DB" heuristic:
- The system treats a DB as "fresh" when no user-created tables exist, or when existing user tables are empty. In that case, rebuilds required by a migration may be applied automatically. For any non-empty DB you should run `sqlite_rebuild.py` explicitly to avoid unexpected destructive changes and to ensure data is preserved/migrated.

### ğŸ›  CLI Tools (examples)

From the project root, two ways to run tools:

- Module-style (recommended after `pip install -e .`):

  ```bash
  # Preview diffs (no files written)
  python -m multi_agent_dashboard.db.infra.generate_migration add_new_feature --dry-run

  # Generate migration files under data/migrations/
  python -m multi_agent_dashboard.db.infra.generate_migration add_new_feature
  ```

- Direct script invocation (no install required; run from repo root):

  ```bash
  python src/multi_agent_dashboard/db/infra/generate_migration.py add_new_feature --dry-run
  python src/multi_agent_dashboard/db/infra/generate_migration.py add_new_feature
  ```

Rebuild examples:

```bash
# Rebuild a single table in-place (with backup)
python -m multi_agent_dashboard.db.infra.sqlite_rebuild agents

# Rebuild all tables with pending FK/constraint diffs
python -m multi_agent_dashboard.db.infra.sqlite_rebuild --all-with-diffs data/db/multi_agent_runs.db
```

Use `--dry-run` to preview rebuild plans before executing. The rebuild tool creates backups by default.

---

## ğŸ§ª Development Notes

- ğŸ§± **`src/` layout**:
  - Avoids accidental imports from the working directory
  - Always develop with `pip install -e .` for module-style runs and imports

- ğŸ–¼ï¸ **Engine/UI separation**:
  - Keep Streamlit-specific code in `multi_agent_dashboard/ui`
  - Engine (`engine.py`) and services (`services.py`) should remain UI-agnostic for reuse in scripts/tests

- ğŸ—ƒï¸ **DB access layering**:
  - `db/infra`: low-level connections, schema, migrations
  - `db/*.py`: DAOs for agents, pipelines, runs, metrics
  - `db/services.py`: higher-level transactional APIs used by the UI and other frontends

- ğŸ” **Prompt safety & caps**:
  - Use `utils.safe_format` for prompt formatting
  - Respect centralized caps (`AGENT_INPUT_CAP`, `AGENT_OUTPUT_CAP`) to avoid unbounded prompts

- ğŸ¨ **UI theming & symbols**:
  - Shared color and emoji schemes live in `config.py`
  - Avoid hardcoding colors/symbols in UI components

- ğŸ§ª Tests & CI:
  - Unit tests are not yet implemented (help wanted). See "Status & Known Gaps" below for details and how to contribute.

### ğŸ” Typical Schema-Change Flow

To add a new column or table:

1. Update `schema.py` (canonical schema)
2. Run:

   ```bash
   python -m multi_agent_dashboard.db.infra.generate_migration add_new_field --dry-run
   python -m multi_agent_dashboard.db.infra.generate_migration add_new_field
   ```

3. Review the generated SQL in `data/migrations/`
4. Run the app (or a script calling `init_db`) to apply migrations
5. If migration files end with `_REQUIRES_REBUILD` and youâ€™re on a non-empty DB:
   - Run `sqlite_rebuild.py` with `--all-with-diffs` (or per-table) after taking backups

---

## ğŸ§¾ Logging

- Log directory and files:
  - Log path (rotating file): `data/logs/application.log`
  - The app uses a RotatingFileHandler with these parameters:
    - maxBytes = 5 * 1024 * 1024 (5 MB) per file
    - backupCount = 3 (keeps up to 3 rotated backups)
- Logs also stream to stdout for easy Streamlit viewing.

---

## ğŸ” Troubleshooting & FAQ

- Missing `OPENAI_API_KEY`:
  - Symptom: UI appears but LLM calls fail with authentication errors.
  - Fix: Add `OPENAI_API_KEY` to `.env` and restart the app.

- Permission errors writing to `data/`:
  - Symptom: PermissionError when creating DB/logs.
  - Fix: Ensure your user or container has write access to the project directory. Adjust mount options in Docker or CI.

- Python version errors:
  - Symptom: Syntax errors for newer syntax constructs.
  - Fix: Use the project-tested interpreter (this repo is tested with CPython 3.14). Ensure your environment uses a compatible Python >=3.10 if 3.14 is not available.

- Graphviz rendering/export confusion:
  - The Python `graphviz` package is included as a Python dependency in pyproject. A system-level Graphviz installation (the `dot` binary) is only required if you plan to render/export graphs to image/PDF files locally using the Graphviz toolchain. Typical in-browser Streamlit `graphviz_chart` usage does not require the system `dot` binary, but exporting to files (e.g., `graphviz.Source(...).render(...)`) may require installing Graphviz on your OS (e.g., `apt install graphviz` or `brew install graphviz`).

- Migrations showing `_REQUIRES_REBUILD`:
  - Symptom: Migration file name includes `_REQUIRES_REBUILD`.
  - Fix: Read the migration comments, back up your DB, and run:
    ```bash
    python -m multi_agent_dashboard.db.infra.sqlite_rebuild --all-with-diffs data/db/multi_agent_runs.db
    ```
    Use `--dry-run` first to preview.

- Tests / CI:
  - Symptom: You expect tests to run but the `tests/` folder is empty or minimal.
  - Fix: Unit tests are currently not implemented.

---

## ğŸ¤ Contributing

To keep the project healthy:

- âœ… Keep UI changes confined to `multi_agent_dashboard/ui`
- ğŸš« Avoid introducing `sys.path` hacks
- ğŸ—ƒï¸ Use DAOs and `services.py` instead of direct SQLite access
- ğŸ§± Always use the migration system for schema changes (see Migration: Safe Workflow)
- ğŸ§  Preserve engine/UI separation; keep the engine free of Streamlit dependencies
- ğŸ§ª Add or extend tests for new engine, DB, or migration behavior where applicable

Developer checklist (quick):
- Create a feature branch
- Update `schema.py` for DB changes (if any)
- Run `generate_migration.py --dry-run`, review diffs, then run without `--dry-run`
- Start the app or run scripts that call `init_db` to apply migrations
- If `_REQUIRES_REBUILD` appears and DB is non-empty, run `sqlite_rebuild.py` with backups
- Add tests for new behavior and include them under `tests/`
- Submit a PR with a clear description and migration notes

---

## ğŸ”§ Status & Known Gaps

- Unit tests: not yet implemented.
- CHANGELOG: not currently maintained â€” a `CHANGELOG.md` would be a helpful addition for releases.
- CI: add checks for linting and tests once a test suite exists.

---

## ğŸ“„ License

This project is licensed under the terms described in the `LICENSE` file in this repository.

---

## ğŸ“ Project History

The project evolved from a single-file Streamlit script into a modular, package-based system featuring:

- ğŸ§  A decoupled multi-agent execution engine with structured results and hooks
- ğŸ•’ Versioned prompt management with atomic agent operations
- ğŸ’¾ Persistent execution history with rich metadata and FK-aware migrations
- ğŸ§± A clean `src/`-based layout for long-term maintainability
- ğŸ—ƒï¸ A DAO + service-based database layer, decoupled from the UI
- ğŸ‘€ First-class observability:
  - Log viewer panel
  - Pipeline warnings
  - Input/output contracts
  - Cost & latency metrics
- ğŸ§© Advanced UX features:
  - File attachments
  - JSON import/export for pipelines and agent templates
  - Ad-hoc pipelines and improved run selection
- ğŸ›  Recent enhancements:
  - Tool-calling and reasoning controls
  - Per-agent colors and symbols reused across graph and selectors
  - Persisted, color-coded logs with search & filters
  - Finer-grained input/output cost tracking
  - Safer migration tooling for foreign-key changes with explicit rebuild helpers

Use this dashboard as both a day-to-day multi-agent playground and a reference architecture for building robust, observable LLM workflows.