# ğŸ¤– Multi-Agent Dashboard

## ğŸ“– Overview

**Multi-Agent Dashboard** is a Streamlit-based Python application for building, managing, and running multi-agent LLM pipelines with:

- ğŸ§  Reusable, UI-agnostic execution engine
- ğŸ’¾ Persistent SQLite storage
- ğŸ‘€ Rich observability (cost, latency, logs, history)
- ğŸ§° Tool calling (incl. web search) with per-agent controls

Use it to prototype agent workflows, compare models and prompts, inspect tool usage, and keep a detailed history of runs.

The project uses a **standard `src/` Python package layout** for clean imports and long-term maintainability.

---

## âš¡ Quick Start (TL;DR)

1. **Clone & enter repo**

   ```bash
   git clone <your-repo-url>
   cd <repo-root>
   ```

2. **Create & activate a virtualenv (recommended)**

   ```bash
   python -m venv .venv
   source .venv/bin/activate        # macOS / Linux
   # .venv\Scripts\activate         # Windows
   ```

3. **Install in editable mode**

   ```bash
   pip install -e .
   ```

4. **Configure environment**

   Create `.env` in the project root:

   ```text
   OPENAI_API_KEY=your_api_key_here
   LOG_LEVEL=INFO
   ```

5. **Run the dashboard**

   From the project root:

   ```bash
   streamlit run src/multi_agent_dashboard/ui/app.py
   ```

6. **Open the app**

   ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

On first run, the app will:

- Create `data/` and subdirectories (if missing)
- Initialize SQLite at `data/db/multi_agent_runs.db`
- Apply SQL migrations from `data/migrations/`
- Seed default agents if the DB is empty

---

## ğŸ§© System Requirements

- ğŸ **Python**: 3.10+ (uses modern typing & standard libraries)
- ğŸ’» **OS**: Tested on macOS and Linux; should work on Windows with appropriate environment setup
- ğŸŒ **Network**: Outbound HTTPS access to OpenAIâ€™s APIs
- ğŸ”‘ **Credentials**: Valid `OPENAI_API_KEY` in `.env`

---

## âš™ï¸ Configuration Reference

Most configuration is centralized in `config.py` and `.env`.

### ğŸŒ± Environment Variables (`.env` at project root)

| Name            | Required | Default | Description                                      |
|-----------------|----------|---------|--------------------------------------------------|
| `OPENAI_API_KEY`| âœ…       | None    | OpenAI API key used by the LLM client           |
| `LOG_LEVEL`     | âŒ       | `INFO`  | Global logging level (`DEBUG`, `INFO`, `WARNING`, `ERROR`) |

If `OPENAI_API_KEY` is missing or invalid, LLM calls will fail at runtime; the UI may load but requests to the model will error.

### ğŸ§± Core Paths & Caps (from `config.py`)

| Setting              | Default                          | Description                                      |
|----------------------|----------------------------------|--------------------------------------------------|
| `PROJECT_ROOT`       | Repo root                       | Auto-detected project root                       |
| `DATA_PATH`          | `PROJECT_ROOT / "data"`         | Root for data and artifacts                      |
| `DB_PATH`            | `DATA_PATH / "db"`              | Directory for SQLite databases                   |
| `DB_FILE_PATH`       | `data/db/multi_agent_runs.db`   | Main SQLite DB file (auto-created)              |
| `MIGRATIONS_PATH`    | `data/migrations`               | Ordered SQL migrations                           |
| `LOGS_PATH`          | `data/logs`                     | Log directory for rotating app logs              |
| `AGENT_INPUT_CAP`    | defined in `config.py`          | Max characters per formatted input segment       |
| `AGENT_OUTPUT_CAP`   | defined in `config.py`          | Max characters per rendered prompt / output      |

Prompt formatting and outputs are passed through `utils.safe_format` using these caps to avoid unbounded prompt sizes.

---

## ğŸš€ Getting Started (Detailed)

### 1ï¸âƒ£ Clone the repository

```bash
git clone <your-repo-url>
cd <repo-root>
```

### 2ï¸âƒ£ Create and activate a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate        # macOS / Linux
# .venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Install the project in editable mode

This is **required** when using a `src/` layout so that `multi_agent_dashboard` is importable:

```bash
pip install -e .
```

### 4ï¸âƒ£ Configure environment variables

Create a `.env` file in the project root:

```text
OPENAI_API_KEY=your_api_key_here
LOG_LEVEL=INFO
```

You can adjust the log level (e.g. `DEBUG`) while developing.

### 5ï¸âƒ£ Run the dashboard

From the project root:

```bash
streamlit run src/multi_agent_dashboard/ui/app.py
```

Then open:

ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

### 6ï¸âƒ£ First Run Behavior

On first successful run, the app will:

- Ensure `data/`, `data/db/`, `data/logs/`, and `data/migrations/` exist
- Create the SQLite DB at:

  ```text
  data/db/multi_agent_runs.db
  ```

- Apply all SQL migrations from `data/migrations/` using the centralized migration system
- Seed default agents (planner/solver/critic/finalizer-style roles) if the `agents` table is empty
- Initialize a rotating log file under `data/logs/`

### ğŸ©º Troubleshooting First Run

- â— **No API key or invalid key**
  - Symptom: UI loads, but model calls fail with authentication/authorization errors.
  - Fix: Set `OPENAI_API_KEY` in `.env`, restart Streamlit.

- â— **Permission issues**
  - Symptom: Errors writing to `data/db` or `data/logs`.
  - Fix: Ensure you have write permissions in the repo directory; adjust Docker/container volume mounts if applicable.

- â— **Python version errors**
  - Symptom: Syntax errors on union types (`str | None`) or similar.
  - Fix: Upgrade to Python 3.10+.

---

## ğŸ§­ Usage

The UI is organized into distinct modes (tabs/pages inside the Streamlit app):

### ğŸ‘¤ Agent Management

Manage reusable agent definitions:

- ğŸ›ï¸ Create, edit, duplicate, delete, rename, and import agents
- ğŸ§© Configure:
  - Model, role, and system prompts
  - Inputs & outputs (with contract validation)
  - Tools (including web search) and reasoning behavior
  - Allowed domains per agent for web tools
  - Color and symbol used in graphs and selectors
- ğŸ•’ Inspect versioned prompt history per agent

Agents are persisted to SQLite and safely versioned, so you can inspect older prompts and configurations.

### ğŸ”— Pipelines (Run Mode)

Build and execute multi-agent pipelines:

- ğŸ”€ Construct pipelines from agents, including:
  - Named, reusable pipelines
  - Ad-hoc pipelines using the current session state
- â–¶ï¸ Run pipelines and inspect:
  - Per-agent inputs and outputs
  - Tool calls and reasoning traces
  - Execution warnings and contract violations
- ğŸ“¤ Export:
  - Pipeline definitions and associated agents as JSON (pipeline-agent export)
  - Final and intermediate outputs for offline analysis

### ğŸ•’ History

Review and analyze previous runs:

- ğŸ“š Browse historical runs stored in SQLite with rich metadata:
  - Models, agent configs, JSON/markdown flags, timing
- ğŸ‘€ Inspect per-run and per-agent outputs
- ğŸ” Compare outputs between agents using a unified diff tool
- ğŸ“Š View cost & latency metrics:
  - Per-run and per-agent cost breakdowns
  - Separate input/output token costs stored alongside totals
- ğŸ“¦ Export full run records (including agent configs and metrics) as JSON

### ğŸ“ File Attachments

Augment runs with files:

- ğŸ“ Attach files to agents and runs
- ğŸ§¬ Automatic MIME-type detection & size limits enforced centrally
- Supports mixed text/binary LLM calls where supported by the model / API

### ğŸ“œ Logs & Observability

Monitor and debug live behavior:

- ğŸ“š Built-in log viewer reads from a rotating log file
- ğŸ¨ Color-coded log levels with search, filters, download, and live updates
- ğŸ§  Logs are written via centralized configuration in `config.py` to both stdout and `data/logs/`

---

## âœ¨ Key Features

### ğŸ§  Engine & Contracts

- ğŸ¤– Multi-agent pipeline execution with a unified dashboard UI
- ğŸ§© Dynamic agent configuration (model, role, inputs/outputs, tools, reasoning behavior, colors, symbols)
- ğŸ§  Strict vs permissive execution modes:
  - Strict mode with explicit input/output contracts and writeback behavior
  - Permissive mode for easier experimentation
- ğŸ§¾ Rich output metadata:
  - JSON vs markdown flags
  - Model identifiers and execution context

### ğŸ”Œ Tools & Reasoning

- ğŸ›  Tool calling:
  - Optional web search tools
  - Per-agent domain restrictions
  - Tool-call traces and agent configurations persisted with each run
- ğŸ§  Reasoning controls:
  - Configurable reasoning effort / style per agent where supported
  - Persisted reasoning and tool-usage configuration per run

### ğŸ’¾ Database & Migrations

- ğŸ’¾ SQLite-backed persistence:
  - Agents and versioned prompts
  - Pipelines and pipeline steps
  - Runs, per-agent outputs, and metrics
- ğŸ§± Centralized migration system:
  - Canonical schema in `db/infra/schema.py`
  - Migration generator (`generate_migration.py`) with FK-aware diffing
  - SQL migrations under `data/migrations/` (e.g. `000_*.sql`, `001_*.sql`, â€¦)
- ğŸ” Foreign key & constraint management:
  - Migrations that require constraint rebuild are tagged with `_REQUIRES_REBUILD`
  - On **fresh (empty) databases**, relevant tables are auto-rebuilt when those migrations run
  - On existing (non-empty) databases, you must run `sqlite_rebuild.py` explicitly for safe rebuilds

### ğŸ“Š Monitoring & Metrics

- ğŸ“Š Cost & latency profiling:
  - Per-run and per-agent metrics with:
    - Input vs output token/cost breakdown
    - Aggregated per-run cost/latency summaries
  - Metrics are persisted and included in JSON exports
- ğŸ‘€ Pipeline visualization:
  - Agent graph view with per-agent colors and symbols
  - Performance and cost overlays

### ğŸ“¤ Import/Export

- ğŸ“¥ Import agent definitions via JSON templates in the UI
- ğŸ“¤ Export:
  - Pipelines + their agents (pipeline-agent export)
  - Per-run history including agent configs, outputs, metrics, and tool usage
- ğŸ§­ Enhanced run selector:
  - Displays run ID, timestamp, agent execution order, and abbreviated task

---

## ğŸ—ï¸ Architecture Overview

The project is organized into clear layers:

- ğŸ›ï¸ **UI Layer (`ui/`)**
  - `ui/app.py`: Streamlit app
  - Handles presentation and user interaction
  - Talks only to services, engine, and models â€” not directly to DB internals

- ğŸ§° **Service Layer (`db/services.py`)**
  - `AgentService`, `RunService`, `PipelineService`
  - Transactional APIs for the UI and scripts
  - Orchestrates DAOs and engine operations

- ğŸ—ƒï¸ **Persistence Layer (`db/*.py`)**
  - DAOs:
    - `agents.py` â€“ agent persistence & prompt versions
    - `pipelines.py` â€“ pipeline specs and steps
    - `runs.py` â€“ run records, outputs, metrics
  - `db.py` â€“ backwards-compatible DB entry points, re-exporting DAOs and providing `init_db`

- ğŸ§± **DB Infrastructure (`db/infra/`)**
  - `core.py` â€“ connection and migrations bootstrap
  - `schema.py` â€“ canonical schema
  - `migrations.py` â€“ migration application logic
  - `generate_migration.py` â€“ CLI to generate migrations from `schema.py`
  - `schema_diff.py`, `schema_diff_constraints.py` â€“ schema diff tools
  - `sqlite_rebuild.py` â€“ safe table rebuild helpers & CLI

- ğŸ§  **Engine & LLM Client**
  - `engine.py` â€“ core multi-agent orchestration engine (UI-agnostic)
  - `llm_client.py` â€“ OpenAI client abstraction with:
    - Typed errors
    - Retries & backoff
    - Tool-calling support
    - Normalized responses for the engine

- ğŸ§© **Models & Utilities**
  - `models.py` â€“ domain models:
    - `AgentSpec`, `AgentRuntime`, `PipelineSpec`, run result types, etc.
  - `utils.py` â€“ shared helpers, including `safe_format` with centralized caps
  - `config.py` â€“ global configuration (paths, pricing tables, logging, caps, colors, symbols)

A typical flow:

```text
UI (Streamlit)
  â†’ Services (AgentService / RunService / PipelineService)
    â†’ DAOs (agents / pipelines / runs)
      â†’ DB (SQLite)
  â†’ Engine (orchestrates agents & LLM calls)
    â†’ LLMClient (OpenAI Responses API + tools)
```

---

## ğŸ—‚ï¸ Repository Structure

```text
repo_root/
â”œâ”€â”€ .env                         # Environment variables (API keys, log level; not committed)
â”œâ”€â”€ .gitignore                   # Ignore sensitive/generated files
â”œâ”€â”€ LICENSE                      # Project license
â”œâ”€â”€ pyproject.toml               # Project metadata, dependencies, packaging config
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ src/
â”‚   â””â”€â”€ multi_agent_dashboard/   # Main Python package (src layout)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py            # Paths, logging, pricing, UI theming, caps
â”‚       â”œâ”€â”€ engine.py            # Core multi-agent orchestration engine
â”‚       â”œâ”€â”€ llm_client.py        # LLM client abstraction (retries, tools, backoff, errors)
â”‚       â”œâ”€â”€ models.py            # Domain models (AgentSpec, PipelineSpec, etc.)
â”‚       â”œâ”€â”€ utils.py             # Shared utilities (safe_format, helpers)
â”‚       â”œâ”€â”€ db/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ agents.py        # Agent DAOs and helpers
â”‚       â”‚   â”œâ”€â”€ db.py            # Backwards-compatible DB entry points + init_db
â”‚       â”‚   â”œâ”€â”€ pipelines.py     # Pipeline DAOs and helpers
â”‚       â”‚   â”œâ”€â”€ runs.py          # Run/agent output DAOs, metrics persistence
â”‚       â”‚   â”œâ”€â”€ services.py      # AgentService, RunService, PipelineService
â”‚       â”‚   â””â”€â”€ infra/
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â”œâ”€â”€ core.py                    # Connection, migrations bootstrap
â”‚       â”‚       â”œâ”€â”€ generate_migration.py      # Migration generator CLI
â”‚       â”‚       â”œâ”€â”€ migrations.py              # Migration application logic
â”‚       â”‚       â”œâ”€â”€ schema.py                  # Canonical schema definition
â”‚       â”‚       â”œâ”€â”€ schema_diff.py             # Column-level diffing
â”‚       â”‚       â”œâ”€â”€ schema_diff_constraints.py # FK / constraints diffing
â”‚       â”‚       â””â”€â”€ sqlite_rebuild.py          # Safe table rebuild helpers & CLI
â”‚       â””â”€â”€ ui/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ agent_editor_mode.py  # Agent CRUD + prompt versioning UI
â”‚           â”œâ”€â”€ app.py                # Streamlit app entrypoint & mode routing
â”‚           â”œâ”€â”€ bootstrap.py          # App setup: DB, clients, engine, defaults
â”‚           â”œâ”€â”€ cache.py              # Streamlit caching helpers
â”‚           â”œâ”€â”€ exports.py            # Pipeline/run export helpers
â”‚           â”œâ”€â”€ graph_view.py         # Pipeline graph visualization
â”‚           â”œâ”€â”€ history_mode.py       # Past runs viewer & export UI
â”‚           â”œâ”€â”€ logging_ui.py         # Log viewer & Streamlit log handler
â”‚           â”œâ”€â”€ metrics_view.py       # Cost & latency metrics UI
â”‚           â”œâ”€â”€ run_mode.py           # Run configuration, execution, results UI
â”‚           â”œâ”€â”€ styles.py             # Streamlit CSS helpers
â”‚           â”œâ”€â”€ tools_view.py         # Tool usage & per-agent tool UI
â”‚           â”œâ”€â”€ utils.py              # UI utility helpers
â”‚           â””â”€â”€ view_models.py        # UI view-model transformations
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ multi_agent_runs.db  # Auto-created SQLite database (not tracked)
â”‚   â”œâ”€â”€ logs/                    # Rotating log files
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 000_*.sql
â”‚       â”œâ”€â”€ 001_*.sql
â”‚       â”œâ”€â”€ 002_*.sql
â”‚       â””â”€â”€ ...                  # Future migrations
â””â”€â”€ tests/                       # Tests (may be empty / future expansion)
```

> ğŸ“ Note: The `data/` directory and its contents are typically created automatically at runtime. The exact set of migration files will evolve over time; see `data/migrations/` in your clone.

---

## ğŸ§¬ Database & Migration Workflow

Database schema management is centralized in `db/infra`.

### ğŸ”§ Initialization

- `init_db(db_path: Path)` (from `db/db.py` and infra) is the canonical way to:
  - Open a connection
  - Ensure migration tracking is set up
  - Apply all pending migrations from `data/migrations/` against the DB file

The Streamlit UI calls this automatically when you run `app.py`.

### ğŸ§± Schema & Migrations

- **Canonical schema**: `db/infra/schema.py`
- **Migrations**: Ordered SQL files in `data/migrations/` (e.g. `000_create_base_tables.sql`, `001_add_agent_output_metadata.sql`, â€¦)
- **Migration application**: `db/infra/migrations.py`:
  - Tracks applied migrations in a dedicated table
  - Applies new migrations in order

### ğŸ§® FK-Aware Changes & Rebuilds

Some schema changes (especially foreign keys and constraints) require table rebuilds. The tooling handles this in two ways:

- `generate_migration.py`:
  - Diffs the current DB schema vs `schema.py`
  - Emits SQL migrations and, when necessary:
    - Attaches `_REQUIRES_REBUILD` to the migration filename
    - Inserts comments/instructions regarding affected tables

- `_REQUIRES_REBUILD` migrations:
  - On a **fresh (empty) DB**:
    - Relevant tables can be auto-rebuilt to match `schema.py` when applying the migration
  - On a **non-empty DB**:
    - The migration is applied but constraints may not fully match `schema.py` until you explicitly run `sqlite_rebuild.py`
    - This design makes destructive rebuilds **opt-in** for non-empty databases

### ğŸ›  CLI Tools

From the project root (using `python -m ...` style):

#### 1. Generate a Migration

```bash
# Preview diffs (no files written)
python -m multi_agent_dashboard.db.infra.generate_migration add_new_feature --dry-run

# Generate migration files under data/migrations/
python -m multi_agent_dashboard.db.infra.generate_migration add_new_feature
```

Key options:

- `name`: required suffix for the migration name
- `--dry-run`: show diffs without writing files
- `--disable-constraints`: ignore constraint diffs if desired

Typical workflow to add a column or table:

1. Edit `schema.py` to describe the target schema
2. Run `generate_migration.py` (with `--dry-run` first)
3. Run again without `--dry-run` to write the SQL
4. Start the app (or run a dedicated script) to apply migrations via `init_db`

#### 2. Rebuild Tables Safely

```bash
# Rebuild a single table in-place (with backup)
python -m multi_agent_dashboard.db.infra.sqlite_rebuild agents

# Rebuild all tables with pending FK/constraint diffs (recommended after *_REQUIRES_REBUILD on non-empty DBs)
python -m multi_agent_dashboard.db.infra.sqlite_rebuild --all-with-diffs
```

Options include `--dry-run` to preview planned rebuilds. The tool creates backups and carefully migrates data to match the canonical schema.

---

## ğŸ§ª Development Notes

- ğŸ§± **`src/` layout**:
  - Avoids accidental imports from the working directory
  - Always develop with `pip install -e .`

- ğŸ–¼ï¸ **Engine/UI separation**:
  - Keep Streamlit-specific code in `multi_agent_dashboard/ui`
  - Engine (`engine.py`) and services (`services.py`) should remain UI-agnostic for reuse in scripts/tests

- ğŸ—ƒï¸ **DB access layering**:
  - `db/infra`: low-level connections, schema, migrations
  - `db/*.py`: DAOs for agents, pipelines, runs, metrics
  - `db/services.py`: higher-level transactional APIs used by the UI and other frontends

- ğŸ” **Prompt safety & caps**:
  - Use `utils.safe_format` for prompt formatting
  - Respect centralized caps (`AGENT_INPUT_CAP`, `AGENT_OUTPUT_CAP`) to avoid unbounded prompts

- ğŸ¨ **UI theming & symbols**:
  - Shared color and emoji schemes live in `config.py`
  - Avoid hardcoding colors/symbols in UI components

### ğŸ” Typical Schema-Change Flow

To add a new column or table:

1. Update `schema.py` (canonical schema)
2. Run:

   ```bash
   python -m multi_agent_dashboard.db.infra.generate_migration add_new_field --dry-run
   python -m multi_agent_dashboard.db.infra.generate_migration add_new_field
   ```

3. Review the generated SQL in `data/migrations/`
4. Run the app (or a script calling `init_db`) to apply migrations
5. If migration files end with `_REQUIRES_REBUILD` and youâ€™re on a non-empty DB:
   - Run `sqlite_rebuild.py` with `--all-with-diffs` (or per-table) after taking backups

---

## ğŸ¤ Contributing

Contributions are welcome. To keep the project healthy:

- âœ… Keep UI changes confined to `multi_agent_dashboard/ui`
- ğŸš« Avoid introducing `sys.path` hacks
- ğŸ—ƒï¸ Use DAOs and `services.py` instead of direct SQLite access
- ğŸ§± Always use the migration system for schema changes
- ğŸ§  Preserve engine/UI separation; keep the engine free of Streamlit dependencies
- ğŸ§ª Add or extend tests for new engine, DB, or migration behavior where applicable

---

## ğŸ“„ License

This project is licensed under the terms described in the `LICENSE` file in this repository.

---

## ğŸ“ Project History

The project evolved from a single-file Streamlit script into a modular, package-based system featuring:

- ğŸ§  A decoupled multi-agent execution engine with structured results and hooks
- ğŸ•’ Versioned prompt management with atomic agent operations
- ğŸ’¾ Persistent execution history with rich metadata and FK-aware migrations
- ğŸ§± A clean `src/`-based layout for long-term maintainability
- ğŸ—ƒï¸ A DAO + service-based database layer, decoupled from the UI
- ğŸ‘€ First-class observability:
  - Log viewer panel
  - Pipeline warnings
  - Input/output contracts
  - Cost & latency metrics
- ğŸ§© Advanced UX features:
  - File attachments
  - JSON import/export for pipelines and agent templates
  - Ad-hoc pipelines and improved run selection
- ğŸ›  Recent enhancements:
  - Tool-calling and reasoning controls
  - Per-agent colors and symbols reused across graph and selectors
  - Persisted, color-coded logs with search & filters
  - Finer-grained input/output cost tracking
  - Safer migration tooling for foreign-key changes with explicit rebuild helpers

Use this dashboard as both a day-to-day multi-agent playground and a reference architecture for building robust, observable LLM workflows.